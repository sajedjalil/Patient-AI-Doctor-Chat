{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:31:50.329918Z",
     "start_time": "2024-10-01T18:31:50.312234Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "# \n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"patient-ai-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "prompt_text = '''You are a helpful AI medical assistant specialized in making medical insights. You also take \n",
    "account patient name, date of birth, medical conditions and medications that are taken by a patient. You will build \n",
    "your responses based on these information and other provided medical knowledge. Now use your medical expertise to \n",
    "provide a comprehensive medical insight for the texts below:'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T21:09:55.176170Z",
     "start_time": "2024-10-01T21:09:55.168860Z"
    }
   },
   "id": "95047fae62a556b5"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727818089.132627 14395629 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727818090.174539 14395629 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import START, StateGraph, MessagesState, END\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, RemoveMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.chains.graph_qa.prompts import CYPHER_GENERATION_PROMPT\n",
    "from langchain.chains import GraphCypherQAChain  \n",
    "from langchain_community.graphs import Neo4jGraph  \n",
    "from langchain_core.documents import Document  \n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "model= ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T21:28:10.751601Z",
     "start_time": "2024-10-01T21:28:09.111Z"
    }
   },
   "id": "4810819cacd0e170"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class State(MessagesState):\n",
    "    name: str\n",
    "    medications: List[str]\n",
    "    medical_conditions: List[str]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T21:28:10.754594Z",
     "start_time": "2024-10-01T21:28:10.753980Z"
    }
   },
   "id": "f632b2c3ea74c1d4"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def fetch_user_info(state: State):\n",
    "    return {\"name\": \"\", \"medications\": [\"a\", \"b\"], \"medical_conditions\": [\"c\"]}\n",
    "\n",
    "# def assistant(state: State):\n",
    "#     # Prompt message\n",
    "#     sys_msg = SystemMessage(content=prompt_text)\n",
    "#     return {\"messages\": [model.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "def query_knowledge_graph(state: State):\n",
    "    graph = Neo4jGraph()\n",
    "    chain = GraphCypherQAChain.from_llm(graph=graph, llm=model, verbose=True, validate_cypher=True, allow_dangerous_requests = True, top_k = 5, cypher_prompt=CYPHER_GENERATION_PROMPT )  \n",
    "    response = chain.invoke({\"query\": messages})  \n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T21:28:11.453521Z",
     "start_time": "2024-10-01T21:28:11.448021Z"
    }
   },
   "id": "ba90b9d446afcc2"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def build_graph() -> StateGraph:\n",
    "    builder = StateGraph(State)\n",
    "    builder.add_node(\"fetch_user_info\", fetch_user_info)\n",
    "    builder.add_node(\"query_knowledge_graph\", query_knowledge_graph)\n",
    "    \n",
    "    builder.add_edge(START, \"fetch_user_info\")\n",
    "    builder.add_edge( \"fetch_user_info\", \"query_knowledge_graph\")\n",
    "    builder.add_edge(\"query_knowledge_graph\", END)\n",
    "    \n",
    "    return builder\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T21:28:12.028314Z",
     "start_time": "2024-10-01T21:28:12.023829Z"
    }
   },
   "id": "8e24f21d030842f"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = build_graph().compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T21:28:13.484564Z",
     "start_time": "2024-10-01T21:28:12.653251Z"
    }
   },
   "id": "78e9e5f60cb67a84"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Did not find url, please add an environment variable `NEO4J_URI` which contains it, or pass `url` as a named parameter.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m messages \u001B[38;5;241m=\u001B[39m [HumanMessage(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMy name is Sajed\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurable\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthread_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m5\u001B[39m\u001B[38;5;124m\"\u001B[39m}}\n\u001B[0;32m----> 5\u001B[0m messages \u001B[38;5;241m=\u001B[39m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m      7\u001B[0m     m\u001B[38;5;241m.\u001B[39mpretty_print()\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1560\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001B[0m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1559\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 1560\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1561\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1562\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1565\u001B[0m \u001B[43m    \u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterrupt_before\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1566\u001B[0m \u001B[43m    \u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterrupt_after\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1567\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdebug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1568\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1569\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1570\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalues\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1571\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlatest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1298\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001B[0m\n\u001B[1;32m   1287\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[1;32m   1288\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001B[39;00m\n\u001B[1;32m   1289\u001B[0m     \u001B[38;5;66;03m# channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[1;32m   1290\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(\n\u001B[1;32m   1293\u001B[0m         input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels,\n\u001B[1;32m   1294\u001B[0m         interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before_,\n\u001B[1;32m   1295\u001B[0m         interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after_,\n\u001B[1;32m   1296\u001B[0m         manager\u001B[38;5;241m=\u001B[39mrun_manager,\n\u001B[1;32m   1297\u001B[0m     ):\n\u001B[0;32m-> 1298\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1299\u001B[0m \u001B[43m            \u001B[49m\u001B[43mloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtasks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1300\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1301\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1302\u001B[0m \u001B[43m            \u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_waiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1303\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# emit output\u001B[39;49;00m\n\u001B[1;32m   1305\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield from\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langgraph/pregel/runner.py:56\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[1;32m     54\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 56\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:29\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy)\u001B[0m\n\u001B[1;32m     27\u001B[0m task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# if successful, end\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:405\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    403\u001B[0m context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, config)\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 405\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:181\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    180\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, config)\n\u001B[0;32m--> 181\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse:\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "Cell \u001B[0;32mIn[46], line 10\u001B[0m, in \u001B[0;36mquery_knowledge_graph\u001B[0;34m(state)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mquery_knowledge_graph\u001B[39m(state: State):\n\u001B[0;32m---> 10\u001B[0m     graph \u001B[38;5;241m=\u001B[39m \u001B[43mNeo4jGraph\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     chain \u001B[38;5;241m=\u001B[39m GraphCypherQAChain\u001B[38;5;241m.\u001B[39mfrom_llm(graph\u001B[38;5;241m=\u001B[39mgraph, llm\u001B[38;5;241m=\u001B[39mmodel, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, validate_cypher\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dangerous_requests \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, top_k \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m, cypher_prompt\u001B[38;5;241m=\u001B[39mCYPHER_GENERATION_PROMPT )  \n\u001B[1;32m     12\u001B[0m     response \u001B[38;5;241m=\u001B[39m chain\u001B[38;5;241m.\u001B[39minvoke({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages})  \n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langchain_community/graphs/neo4j_graph.py:348\u001B[0m, in \u001B[0;36mNeo4jGraph.__init__\u001B[0;34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001B[0m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m    344\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not import neo4j python package. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    345\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease install it with `pip install neo4j`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    346\u001B[0m     )\n\u001B[0;32m--> 348\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[43mget_from_dict_or_env\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43murl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43murl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNEO4J_URI\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;66;03m# if username and password are \"\", assume Neo4j auth is disabled\u001B[39;00m\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m username \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m password \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langchain_core/utils/env.py:51\u001B[0m, in \u001B[0;36mget_from_dict_or_env\u001B[0;34m(data, key, env_key, default)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data[key]\n\u001B[1;32m     49\u001B[0m key_for_err \u001B[38;5;241m=\u001B[39m key[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)) \u001B[38;5;28;01melse\u001B[39;00m key\n\u001B[0;32m---> 51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_from_env\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey_for_err\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Patient_Chat/venv/lib/python3.12/site-packages/langchain_core/utils/env.py:76\u001B[0m, in \u001B[0;36mget_from_env\u001B[0;34m(key, env_key, default)\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 76\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     77\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDid not find \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, please add an environment variable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     78\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00menv_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` which contains it, or pass\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` as a named parameter.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     80\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Did not find url, please add an environment variable `NEO4J_URI` which contains it, or pass `url` as a named parameter."
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "messages = [HumanMessage(content=\"My name is Sajed\")]\n",
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "messages = graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()\n",
    "    \n",
    "pprint(messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T21:29:23.845259Z",
     "start_time": "2024-10-01T21:29:23.285659Z"
    }
   },
   "id": "f6ad6c70c901ebd6"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "My name is Sajed\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "It's nice to meet you Sajed. As an AI medical assistant, I'm happy to chat with you about health-related topics. How can I assist you today? Please let me know if you have any questions about your health, medication, lifestyle, or if you need help with any medical requests like appointment scheduling or medication changes. I'm here to help in whatever way I can.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "My name is Sajed\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Okay, got it. I understand your name is Sajed. As an AI medical assistant, I'm happy to chat with you about any health-related topics you'd like to discuss. Please feel free to ask me questions about your health, medication, lifestyle, or if you need assistance with things like making appointments or requesting medication changes. I'm here to help in any way I can.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "My name is Sajed\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I apologize, but I do not need to keep repeating that your name is Sajed. I heard and understood that the first time you mentioned it. As an AI medical assistant, I'm happy to have a conversation with you about any health-related topics you would like to discuss. Please let me know if you have any specific questions or requests, and I'll do my best to provide helpful information or utilize the relevant tools I have available. How else can I assist you today?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name? and I have fever now\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Okay, let's move our discussion in a more productive direction. You mentioned you have a fever now. That sounds concerning. As your medical assistant, a few questions to better understand your situation:\n",
      "\n",
      "- How long have you been experiencing the fever?\n",
      "- Do you have any other symptoms like body aches, chills, or a sore throat?\n",
      "- Have you taken any medication to try to reduce the fever?\n",
      "- Is there anything else going on with your health that I should be aware of?\n",
      "\n",
      "Providing me with some more details about your fever and overall condition will allow me to better assist you. My role is to help you get the appropriate medical care and advice for managing your health concerns. Please let me know the details, and I'll do my best to provide helpful guidance.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name? and I have fever now\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I apologize, but I do not actually know your name. As an AI assistant, I do not have prior knowledge of your identity or personal information. \n",
      "\n",
      "Regarding your fever, that is certainly something I can try to assist with. Can you please provide me with some more details about your symptoms and situation? For example:\n",
      "\n",
      "- How long have you been experiencing the fever?\n",
      "- What is the temperature reading?\n",
      "- Do you have any other symptoms like chills, body aches, or a sore throat?\n",
      "- Have you taken any medication to try to reduce the fever?\n",
      "- Is there anything else going on with your health that I should be aware of?\n",
      "\n",
      "With more specifics about your medical condition, I can better evaluate the situation and provide appropriate guidance or recommend next steps. My role is to give you helpful advice to manage your health concerns. Please let me know the details, and I'll do my best to assist you.\n",
      "{'medical_insights': 'No medical insights available.\\n'\n",
      "                     '\\n'\n",
      "                     'The conversation did not provide enough specific medical '\n",
      "                     'information for me to analyze or make any meaningful '\n",
      "                     'medical insights. The user repeatedly asked about their '\n",
      "                     'name, which is not a medical concern, and simply stated '\n",
      "                     'they have a fever, without providing any additional '\n",
      "                     'details about the fever or their overall health '\n",
      "                     'condition. Without more concrete medical details from '\n",
      "                     'the user, I do not have sufficient information to '\n",
      "                     'provide any useful medical analysis or insights. The '\n",
      "                     'conversation remained quite general and did not delve '\n",
      "                     \"into specifics about the user's health status or \"\n",
      "                     'symptoms.',\n",
      " 'messages': [HumanMessage(content='My name is Sajed', additional_kwargs={}, response_metadata={}, id='2c71951e-25e3-419e-b716-3fd6b1d8ceed'),\n",
      "              AIMessage(content=\"It's nice to meet you Sajed. As an AI medical assistant, I'm happy to chat with you about health-related topics. How can I assist you today? Please let me know if you have any questions about your health, medication, lifestyle, or if you need help with any medical requests like appointment scheduling or medication changes. I'm here to help in whatever way I can.\", additional_kwargs={}, response_metadata={'id': 'msg_01MbhiwnTnejDcLwnycXuQ1T', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 700, 'output_tokens': 83}}, id='run-3a574842-aec1-4ae0-9f22-a62899f77b40-0', usage_metadata={'input_tokens': 700, 'output_tokens': 83, 'total_tokens': 783}),\n",
      "              HumanMessage(content='My name is Sajed', additional_kwargs={}, response_metadata={}, id='9bf9fc61-a4a5-4777-8a2c-78e8923e1953'),\n",
      "              AIMessage(content=\"Okay, got it. I understand your name is Sajed. As an AI medical assistant, I'm happy to chat with you about any health-related topics you'd like to discuss. Please feel free to ask me questions about your health, medication, lifestyle, or if you need assistance with things like making appointments or requesting medication changes. I'm here to help in any way I can.\", additional_kwargs={}, response_metadata={'id': 'msg_019oW4hPRiUWsNp3bhMfvmtA', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 792, 'output_tokens': 83}}, id='run-a96f3206-5564-4347-b348-60d433d5eb28-0', usage_metadata={'input_tokens': 792, 'output_tokens': 83, 'total_tokens': 875}),\n",
      "              HumanMessage(content='My name is Sajed', additional_kwargs={}, response_metadata={}, id='32361da2-c7a1-46aa-9576-9649fd6055c0'),\n",
      "              AIMessage(content=\"I apologize, but I do not need to keep repeating that your name is Sajed. I heard and understood that the first time you mentioned it. As an AI medical assistant, I'm happy to have a conversation with you about any health-related topics you would like to discuss. Please let me know if you have any specific questions or requests, and I'll do my best to provide helpful information or utilize the relevant tools I have available. How else can I assist you today?\", additional_kwargs={}, response_metadata={'id': 'msg_01BYcuh9evYiaRiNZiA9oft3', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 885, 'output_tokens': 103}}, id='run-4761a3f5-c9aa-425c-95ae-a6bc0a0beb35-0', usage_metadata={'input_tokens': 885, 'output_tokens': 103, 'total_tokens': 988}),\n",
      "              HumanMessage(content='What is my name? and I have fever now', additional_kwargs={}, response_metadata={}, id='ab700720-7346-45a4-94b5-a8e917699aa5'),\n",
      "              AIMessage(content=\"Okay, let's move our discussion in a more productive direction. You mentioned you have a fever now. That sounds concerning. As your medical assistant, a few questions to better understand your situation:\\n\\n- How long have you been experiencing the fever?\\n- Do you have any other symptoms like body aches, chills, or a sore throat?\\n- Have you taken any medication to try to reduce the fever?\\n- Is there anything else going on with your health that I should be aware of?\\n\\nProviding me with some more details about your fever and overall condition will allow me to better assist you. My role is to help you get the appropriate medical care and advice for managing your health concerns. Please let me know the details, and I'll do my best to provide helpful guidance.\", additional_kwargs={}, response_metadata={'id': 'msg_01Lf2PL6W6CtvASJMinW79C6', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 1001, 'output_tokens': 167}}, id='run-45747a5e-8dcb-4bc0-a1f9-5941257f2d56-0', usage_metadata={'input_tokens': 1001, 'output_tokens': 167, 'total_tokens': 1168}),\n",
      "              HumanMessage(content='What is my name? and I have fever now', additional_kwargs={}, response_metadata={}, id='67b0c386-20d0-483d-89e8-5c1363a5bdbb'),\n",
      "              AIMessage(content=\"I apologize, but I do not actually know your name. As an AI assistant, I do not have prior knowledge of your identity or personal information. \\n\\nRegarding your fever, that is certainly something I can try to assist with. Can you please provide me with some more details about your symptoms and situation? For example:\\n\\n- How long have you been experiencing the fever?\\n- What is the temperature reading?\\n- Do you have any other symptoms like chills, body aches, or a sore throat?\\n- Have you taken any medication to try to reduce the fever?\\n- Is there anything else going on with your health that I should be aware of?\\n\\nWith more specifics about your medical condition, I can better evaluate the situation and provide appropriate guidance or recommend next steps. My role is to give you helpful advice to manage your health concerns. Please let me know the details, and I'll do my best to assist you.\", additional_kwargs={}, response_metadata={'id': 'msg_016WT7xNB1mepeN7zFHt23K3', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 1181, 'output_tokens': 199}}, id='run-d5d6716c-59bf-43e4-80e4-7bf8a5befdd4-0', usage_metadata={'input_tokens': 1181, 'output_tokens': 199, 'total_tokens': 1380})],\n",
      " 'summary': 'Okay, let me extend the summary to include the latest part of our '\n",
      "            'conversation:\\n'\n",
      "            '\\n'\n",
      "            'The conversation began with me introducing myself as an AI '\n",
      "            'medical assistant and offering to assist you with any '\n",
      "            'health-related questions or requests. You then stated your name '\n",
      "            'is Sajed. I acknowledged and confirmed that I had heard your '\n",
      "            'name. \\n'\n",
      "            '\\n'\n",
      "            'When you repeated \"My name is Sajed\" a few more times, I '\n",
      "            'clarified that I had understood your name the first time and did '\n",
      "            \"not need to keep repeating it. I reiterated that I'm here to have \"\n",
      "            \"a helpful conversation with you about any health topics you'd \"\n",
      "            'like to discuss.\\n'\n",
      "            '\\n'\n",
      "            'You then stated that you have a fever. I responded by asking '\n",
      "            'follow-up questions to better understand your medical situation, '\n",
      "            \"such as how long you've had the fever, if you have any other \"\n",
      "            \"symptoms, and if you've taken any medication. I emphasized that \"\n",
      "            'as your medical assistant, my role is to provide helpful guidance '\n",
      "            'for managing your health concerns.\\n'\n",
      "            '\\n'\n",
      "            'In the latest messages, you\\'ve simply repeated \"What is my name? '\n",
      "            'and I have fever now\" a few times. I\\'ve explained that as an AI, '\n",
      "            'I do not have prior knowledge of your name or personal '\n",
      "            \"information. However, I've continued to focus the conversation on \"\n",
      "            'addressing your reported fever, reiterating my desire to provide '\n",
      "            'useful medical advice if you can give me more details about your '\n",
      "            'symptoms and condition.\\n'\n",
      "            '\\n'\n",
      "            'Please let me know if this extended summary accurately captures '\n",
      "            \"the key points of our conversation so far. I'm happy to clarify \"\n",
      "            'or expand on anything as needed.'}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is my name? and I have fever now\")]\n",
    "messages = graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()\n",
    "    \n",
    "pprint(messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:42:00.689533Z",
     "start_time": "2024-10-01T18:41:49.757866Z"
    }
   },
   "id": "d5f776f77ca58fc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e05b0b06cdddb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is my name?\")]\n",
    "messages = graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd8d9b0ed8c3f2df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26e55bff0f0c6fdb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"I have an appointmnet on October 9. I want to reschedule it to November 5th.\")]\n",
    "messages = graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f89bb14dad789feb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.get_state(thread).values.get(\"summary\",\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19adfb478770ac65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "19d48e7971aa57c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
